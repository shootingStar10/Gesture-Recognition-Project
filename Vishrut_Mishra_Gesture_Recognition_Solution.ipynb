{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d9af76",
   "metadata": {},
   "source": [
    "# Gesture Recognition with Neural Network\n",
    "\n",
    "- **Problem Statement:** Imagine you are working as a data scientist at a home electronics company which manufactures state of the art smart televisions. You want to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote. The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:\n",
    "\n",
    "  - *Thumbs up:*  Increase the volume\n",
    "  - *Thumbs down:* Decrease the volume\n",
    "  - *Left swipe:* 'Jump' backwards 10 seconds\n",
    "  - *Right swipe:* 'Jump' forward 10 seconds  \n",
    "  - *Stop:* Pause the movie\n",
    " \n",
    "### 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f0681e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "import cv2\n",
    "import datetime\n",
    "from tensorflow.keras.layers import Conv3D, Dense, Flatten, BatchNormalization, Dropout, TimeDistributed, GRU, GlobalMaxPooling2D, MaxPooling3D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956474e3",
   "metadata": {},
   "source": [
    "### 1. Constants Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3954b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset paths\n",
    "TRAIN_DOC_PATH = 'datasets/Project_data/train.csv'\n",
    "TEST_DOC_PATH = 'datasets/Project_data/val.csv'\n",
    "TRAIN_DATA_PATH = '/datasets/Project_data/train'\n",
    "TEST_DATA_PATH = '/datasets/Project_data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84723753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed initializations\n",
    "np.random.seed(30)\n",
    "tf.random.set_seed(30)\n",
    "rn.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3012830b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# frames =  30\n",
      "# dim =  (100, 100)\n",
      "# training sequences = 663\n",
      "# validation sequences = 100\n"
     ]
    }
   ],
   "source": [
    "frames = 30\n",
    "print('# frames = ', frames)\n",
    "dim = (100, 100)\n",
    "print('# dim = ', dim)\n",
    "curr_dt_time = datetime.datetime.now()\n",
    "num_train_sequences = len(np.random.permutation(open(TRAIN_DOC_PATH).readlines()))\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(np.random.permutation(open(TEST_DOC_PATH).readlines()))\n",
    "print('# validation sequences =', num_val_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b58e03f",
   "metadata": {},
   "source": [
    "### 2. Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "902cf51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator function\n",
    "def data_generator(data_dir_path, data_doc_path, batch_size):\n",
    "    \"\"\"\n",
    "    Generator function to generate the data in batches\n",
    "    # param- data_dir_path: directory path of train and test data\n",
    "    # param- data_doc_path: directory path of .csv where all folders list is present\n",
    "    # param- batch_size: size of a batch\n",
    "    # param- frames: number of frames(images) you want to use in a video\n",
    "    # param- dim: dimension of a image in form of (w, h)\n",
    "    # returns- batch_data and batch_labels\n",
    "    \"\"\"\n",
    "    print('\\nSource path = ', data_dir_path, '; batch size =', batch_size)\n",
    "    num_of_images = [i for i in range(0, frames)]\n",
    "    \n",
    "    while True:\n",
    "        doc = np.random.permutation(open(data_doc_path).readlines())\n",
    "        num_batches = len(doc) // batch_size\n",
    "        \n",
    "        # increase batchsize by 1 to store extra images if doc_len is not divisible by batch_size\n",
    "        if len(doc) % batch_size != 0:\n",
    "            num_batches += 1\n",
    "\n",
    "        for batch in range(0, num_batches):\n",
    "            # adjust last batch size according to remaining number of images\n",
    "            if len(doc) % batch_size != 0 and batch == num_batches-1:\n",
    "                batch_size = len(doc) - (batch*batch_size)\n",
    "            \n",
    "            batch_data = np.zeros((batch_size, frames, dim[0], dim[1], 3))\n",
    "            batch_labels = np.zeros((batch_size, 5))\n",
    "\n",
    "            for folder in range(0, batch_size):\n",
    "                folder_idx = folder + (batch*batch_size)\n",
    "\n",
    "                images = os.listdir(data_dir_path + '/' + doc[folder_idx].split(';')[0])\n",
    "\n",
    "                for img_idx, item in enumerate(num_of_images):\n",
    "                    image = cv2.imread(data_dir_path+'/'+ doc[folder_idx].strip().split(';')[0]+'/'+images[item]).astype(np.float32)\n",
    "                    image = image_processing(image, dim)\n",
    "                    batch_data[folder, img_idx, :, :, 0] = image[:, :, 0] / 255.0\n",
    "                    batch_data[folder, img_idx, :, :, 1] = image[:, :, 1] / 255.0\n",
    "                    batch_data[folder, img_idx, :, :, 2] = image[:, :, 2] / 255.0\n",
    "\n",
    "                batch_labels[folder, int(doc[folder_idx].split(';')[-1])] = 1\n",
    "            yield batch_data, batch_labels\n",
    "\n",
    "## ----------------------------------------------------------------##\n",
    "\n",
    "# utility for image processing\n",
    "def image_processing(image, dim):\n",
    "    image = crop_image(image)\n",
    "    image = resize_image(image, dim)\n",
    "    return image   \n",
    "\n",
    "## ----------------------------------------------------------------##\n",
    "\n",
    "# utility to resize image\n",
    "def resize_image(image, dim):\n",
    "    return cv2.resize(image, dim)\n",
    "\n",
    "## ----------------------------------------------------------------##\n",
    "\n",
    "# utility to crop image\n",
    "def crop_image(image):\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Define the size of the cropping box\n",
    "    crop_width = 120  # Width of the cropped region\n",
    "    crop_height = 120  # Height of the cropped region\n",
    "\n",
    "    # Calculate the center of the image\n",
    "    center_x, center_y = width // 2, height // 2\n",
    "\n",
    "    # Calculate the coordinates of the cropping box\n",
    "    start_x = max(center_x - crop_width // 2, 0)\n",
    "    end_x = min(center_x + crop_width // 2, width)\n",
    "    start_y = max(center_y - crop_height // 2, 0)\n",
    "    end_y = min(center_y + crop_height // 2, height)\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_image = image[start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26991d13",
   "metadata": {},
   "source": [
    "### 3. 3D-CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bedee001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility to run the model\n",
    "def run_model(model, batch_size, num_epochs, model_init='model_init', save=False):\n",
    "    callbacks_list = []\n",
    "    \n",
    "    if save == True:\n",
    "        model_name = model_init + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "\n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "\n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.4f}-{categorical_accuracy:.4f}-{val_loss:.4f}-{val_categorical_accuracy:.4f}.h5'\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', save_best_only=True, mode='auto', verbose=1)\n",
    "        callbacks_list.append(checkpoint)\n",
    "\n",
    "    # define callbacks\n",
    "    LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "    callbacks_list.append(LR)\n",
    "\n",
    "    # define step size for train and test\n",
    "    if (num_train_sequences%batch_size) == 0:\n",
    "        steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "    else:\n",
    "        steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "    \n",
    "    if (num_val_sequences%batch_size) == 0:\n",
    "        validation_steps = int(num_val_sequences/batch_size)\n",
    "    else:\n",
    "        validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "    print('Steps per epoch = ', steps_per_epoch)\n",
    "    print('Validation steps = ', validation_steps)\n",
    "    \n",
    "    # data generation\n",
    "    train_data_generator = data_generator(TRAIN_DATA_PATH, TRAIN_DOC_PATH, batch_size)\n",
    "    test_data_generator = data_generator(TEST_DATA_PATH, TEST_DOC_PATH, batch_size)\n",
    "    \n",
    "    # train and validate model\n",
    "    model.fit_generator(train_data_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, validation_data=test_data_generator, \n",
    "               validation_steps=validation_steps, callbacks=callbacks_list, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab058f1a",
   "metadata": {},
   "source": [
    "### Experiment-1: 3D CNN with 3 convolutions, kernal_size=(3,3,3), batch size=32, without padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a506042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 28, 98, 98, 32)    2624      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 14, 49, 49, 32)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 12, 47, 47, 64)    55360     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 6, 23, 23, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 4, 21, 21, 128)    221312    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4, 21, 21, 128)    0         \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 2, 10, 10, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3276928   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,564,805\n",
      "Trainable params: 3,564,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Steps per epoch =  21\n",
      "Validation steps =  4\n",
      "\n",
      "Source path =  /datasets/Project_data/train ; batch size = 32\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 05:00:18.584763: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 1.6562 - categorical_accuracy: 0.2006\n",
      "Source path =  /datasets/Project_data/val ; batch size = 32\n",
      "21/21 [==============================] - 102s 5s/step - loss: 1.6562 - categorical_accuracy: 0.2006 - val_loss: 1.5934 - val_categorical_accuracy: 0.1900 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 43s 2s/step - loss: 1.5563 - categorical_accuracy: 0.2567 - val_loss: 1.5694 - val_categorical_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 30s 1s/step - loss: 1.5662 - categorical_accuracy: 0.2974 - val_loss: 1.5292 - val_categorical_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 25s 1s/step - loss: 1.4187 - categorical_accuracy: 0.3609 - val_loss: 1.2208 - val_categorical_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 23s 1s/step - loss: 1.4005 - categorical_accuracy: 0.3894 - val_loss: 1.3539 - val_categorical_accuracy: 0.3125 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# hyperparameters\n",
    "kernel_size = (3, 3, 3)\n",
    "pool_size = (2, 2, 2)\n",
    "\n",
    "# model definition\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(32, kernel_size, input_shape=(frames, dim[0], dim[1], 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(64, kernel_size, activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(128, kernel_size, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['categorical_accuracy'])\n",
    "\n",
    "# run model\n",
    "run_model(model=model, batch_size=32, num_epochs=5, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0368a7",
   "metadata": {},
   "source": [
    "### Experiment-2: 3D CNN with 4 convolutions, kernal_size=(3,3,3), batch size=32, with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f1edfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 30, 100, 100, 16)  1312      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 15, 50, 50, 16)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 15, 50, 50, 32)    13856     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 7, 25, 25, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 7, 25, 25, 64)     55360     \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 3, 12, 12, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 3, 12, 12, 128)    221312    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 12, 12, 128)    0         \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 1, 6, 6, 128)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                294976    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 591,301\n",
      "Trainable params: 591,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Steps per epoch =  21\n",
      "Validation steps =  4\n",
      "\n",
      "Source path =  /datasets/Project_data/train ; batch size = 32\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6367 - categorical_accuracy: 0.2066\n",
      "Source path =  /datasets/Project_data/val ; batch size = 32\n",
      "21/21 [==============================] - 46s 2s/step - loss: 1.6367 - categorical_accuracy: 0.2066 - val_loss: 1.6066 - val_categorical_accuracy: 0.2900 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 27s 1s/step - loss: 1.5762 - categorical_accuracy: 0.2195 - val_loss: 1.4112 - val_categorical_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 24s 1s/step - loss: 1.5279 - categorical_accuracy: 0.2646 - val_loss: 1.5463 - val_categorical_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.4594 - categorical_accuracy: 0.3358 - val_loss: 1.4965 - val_categorical_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 20s 972ms/step - loss: 1.3999 - categorical_accuracy: 0.3669 - val_loss: 1.4012 - val_categorical_accuracy: 0.3750 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# hyperparameters\n",
    "kernel_size = (3, 3, 3)\n",
    "pool_size = (2, 2, 2)\n",
    "\n",
    "# model definition\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(16, kernel_size, input_shape=(frames, dim[0], dim[1], 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(32, kernel_size, activation='relu', padding='same'))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(64, kernel_size, activation='relu', padding='same'))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(128, kernel_size, activation='relu', padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['categorical_accuracy'])\n",
    "\n",
    "# run model\n",
    "run_model(model=model, batch_size=32, num_epochs=5, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ce15a",
   "metadata": {},
   "source": [
    "### Experiment-3 3D CNN with 4 convolutions, kernal_size=(2, 2, 2), batch size=16, with batch normalization & without padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35c5dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 29, 99, 99, 32)    800       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 29, 99, 99, 32)   128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 29, 99, 99, 32)    0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 29, 99, 99, 32)    0         \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 28, 98, 98, 32)    8224      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 98, 98, 32)   128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 28, 98, 98, 32)    0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 28, 98, 98, 32)    0         \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 14, 49, 49, 32)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 13, 48, 48, 64)    16448     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 48, 48, 64)   256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 13, 48, 48, 64)    0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 13, 48, 48, 64)    0         \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 12, 47, 47, 64)    32832     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 12, 47, 47, 64)   256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 12, 47, 47, 64)    0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 12, 47, 47, 64)    0         \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 6, 23, 23, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 203136)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               104006144 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,067,781\n",
      "Trainable params: 104,067,397\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Steps per epoch =  42\n",
      "Validation steps =  7\n",
      "\n",
      "Source path =  /datasets/Project_data/train ; batch size = 16\n",
      "Epoch 1/5\n",
      "42/42 [==============================] - ETA: 0s - loss: 132.0036 - categorical_accuracy: 0.2745\n",
      "Source path =  /datasets/Project_data/val ; batch size = 16\n",
      "42/42 [==============================] - 44s 1s/step - loss: 132.0036 - categorical_accuracy: 0.2745 - val_loss: 21.8958 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "42/42 [==============================] - 18s 430ms/step - loss: 28.5286 - categorical_accuracy: 0.3741 - val_loss: 15.0079 - val_categorical_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "42/42 [==============================] - 17s 412ms/step - loss: 13.3526 - categorical_accuracy: 0.3333 - val_loss: 2.0134 - val_categorical_accuracy: 0.1786 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "42/42 [==============================] - 13s 324ms/step - loss: 1.7572 - categorical_accuracy: 0.2696 - val_loss: 1.6113 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "42/42 [==============================] - 14s 336ms/step - loss: 1.7821 - categorical_accuracy: 0.2571 - val_loss: 1.6092 - val_categorical_accuracy: 0.0714 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# hyperparameters\n",
    "kernel_size = (2, 2, 2)\n",
    "pool_size = (2, 2, 2)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(filters=32, kernel_size=(2, 2, 2), input_shape=(frames, dim[0], dim[1], 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv3D(filters=32, kernel_size=(2, 2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(filters=64, kernel_size=(2, 2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv3D(filters=64, kernel_size=(2, 2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['categorical_accuracy'])\n",
    "\n",
    "# run model\n",
    "run_model(model=model, batch_size=16, num_epochs=5, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d01243",
   "metadata": {},
   "source": [
    "### Experiment-4 3D CNN with 3 convolutions, kernal_size=(2,2,2), batch size=32, without padding & with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a2e7da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 29, 99, 99, 32)    800       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 29, 99, 99, 32)   128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 29, 99, 99, 32)    0         \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 14, 49, 49, 32)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 13, 48, 48, 64)    16448     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 13, 48, 48, 64)   256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 13, 48, 48, 64)    0         \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 6, 24, 24, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 5, 23, 23, 128)    65664     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 5, 23, 23, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 5, 23, 23, 128)    0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 23, 23, 128)    0         \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 2, 11, 11, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3965056   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,057,445\n",
      "Trainable params: 4,056,997\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Steps per epoch =  21\n",
      "Validation steps =  4\n",
      "\n",
      "Source path =  /datasets/Project_data/train ; batch size = 32\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - ETA: 0s - loss: 9.5772 - categorical_accuracy: 0.2670\n",
      "Source path =  /datasets/Project_data/val ; batch size = 32\n",
      "21/21 [==============================] - 42s 2s/step - loss: 9.5772 - categorical_accuracy: 0.2670 - val_loss: 1.6504 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 27s 1s/step - loss: 3.1866 - categorical_accuracy: 0.3954 - val_loss: 1.9110 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 23s 1s/step - loss: 2.2692 - categorical_accuracy: 0.4192 - val_loss: 1.7133 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 23s 1s/step - loss: 1.6764 - categorical_accuracy: 0.4336 - val_loss: 1.8716 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5759 - categorical_accuracy: 0.4314\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "21/21 [==============================] - 20s 982ms/step - loss: 1.5759 - categorical_accuracy: 0.4314 - val_loss: 2.4849 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# hyperparameters\n",
    "kernel_size = (2, 2, 2)\n",
    "pool_size = (2, 2, 2)\n",
    "\n",
    "# model definition\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(32, kernel_size, input_shape=(frames, dim[0], dim[1], 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(64, kernel_size))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(128, kernel_size))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['categorical_accuracy'])\n",
    "\n",
    "# run model\n",
    "run_model(model=model, batch_size=32, num_epochs=5, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc63422f",
   "metadata": {},
   "source": [
    "### Experiment-5: 3D CNN with 3 convolutions, kernal_size=(2,2,2), batch size=32, without padding (Best model) \n",
    "\n",
    "This model has following architecture:\n",
    "\n",
    "- Input size = (100, 100, 3)\n",
    "- Batch size = 32\n",
    "- 3D convolutional layer with 32 filters, standard kernel size of (2,2,2) and `relu` activation function.\n",
    "- 3D maxpooling with pool size of (2,2,2)\n",
    "- 3D convolutional layer with 64 filters, standard kernel size of (2,2,2) and `relu` activation function.\n",
    "- 3D maxpooling with pool size of (2,2,2)\n",
    "- 3D convolutional layer with 128 filters, standard kernel size of (2,2,2) and `relu` activation function.\n",
    "- 3D maxpooling with pool size of (2,2,2)\n",
    "- Flatten layer\n",
    "- 2 Dense layers with 128 and 64 neurons respectively with `relu` activation function.\n",
    "- Output layer with 5 neurons and `softmax` activation function.\n",
    "- Optimiser used is `Adam`\n",
    "- Loss used is `categorical_crossentropy`\n",
    "- Best accuracy\n",
    "    - Train: 89.64%\n",
    "    - Test:  87.50%\n",
    "- Best loss\n",
    "    - Train: 0.2785\n",
    "    - Test:  0.5316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f4d3f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 29, 99, 99, 32)    800       \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 14, 49, 49, 32)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 13, 48, 48, 64)    16448     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 6, 24, 24, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 5, 23, 23, 128)    65664     \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 2, 11, 11, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3965056   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,056,549\n",
      "Trainable params: 4,056,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Steps per epoch =  21\n",
      "Validation steps =  4\n",
      "\n",
      "Source path =  /datasets/Project_data/train ; batch size = 32\n",
      "Epoch 1/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6222 - categorical_accuracy: 0.1991\n",
      "Source path =  /datasets/Project_data/val ; batch size = 32\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.26000, saving model to 3D_CNN_2024-09-0204_47_59.216946/model-00001-1.6222-0.1991-1.5052-0.2600.h5\n",
      "21/21 [==============================] - 42s 2s/step - loss: 1.6222 - categorical_accuracy: 0.1991 - val_loss: 1.5052 - val_categorical_accuracy: 0.2600 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4800 - categorical_accuracy: 0.3230\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.26000 to 0.56250, saving model to 3D_CNN_2024-09-0204_47_59.216946/model-00002-1.4800-0.3230-1.2928-0.5625.h5\n",
      "21/21 [==============================] - 27s 1s/step - loss: 1.4800 - categorical_accuracy: 0.3230 - val_loss: 1.2928 - val_categorical_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3523 - categorical_accuracy: 0.4379\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.56250\n",
      "21/21 [==============================] - 24s 1s/step - loss: 1.3523 - categorical_accuracy: 0.4379 - val_loss: 1.4134 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2577 - categorical_accuracy: 0.4561\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.56250\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.2577 - categorical_accuracy: 0.4561 - val_loss: 1.2564 - val_categorical_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0187 - categorical_accuracy: 0.6218\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.56250\n",
      "21/21 [==============================] - 20s 977ms/step - loss: 1.0187 - categorical_accuracy: 0.6218 - val_loss: 1.1318 - val_categorical_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9370 - categorical_accuracy: 0.6415\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.56250\n",
      "21/21 [==============================] - 20s 997ms/step - loss: 0.9370 - categorical_accuracy: 0.6415 - val_loss: 1.4363 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.7292 - categorical_accuracy: 0.7367\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.56250\n",
      "21/21 [==============================] - 20s 1s/step - loss: 0.7292 - categorical_accuracy: 0.7367 - val_loss: 1.3376 - val_categorical_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.7646 - categorical_accuracy: 0.7283\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.56250\n",
      "21/21 [==============================] - 19s 950ms/step - loss: 0.7646 - categorical_accuracy: 0.7283 - val_loss: 1.2546 - val_categorical_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.5703 - categorical_accuracy: 0.7871\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.56250 to 0.81250, saving model to 3D_CNN_2024-09-0204_47_59.216946/model-00009-0.5703-0.7871-0.6878-0.8125.h5\n",
      "21/21 [==============================] - 19s 941ms/step - loss: 0.5703 - categorical_accuracy: 0.7871 - val_loss: 0.6878 - val_categorical_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4625 - categorical_accuracy: 0.8067\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.81250\n",
      "21/21 [==============================] - 20s 990ms/step - loss: 0.4625 - categorical_accuracy: 0.8067 - val_loss: 1.5300 - val_categorical_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3999 - categorical_accuracy: 0.8627\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.81250\n",
      "21/21 [==============================] - 20s 999ms/step - loss: 0.3999 - categorical_accuracy: 0.8627 - val_loss: 1.0496 - val_categorical_accuracy: 0.6875 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2785 - categorical_accuracy: 0.8964\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.81250 to 0.87500, saving model to 3D_CNN_2024-09-0204_47_59.216946/model-00012-0.2785-0.8964-0.5316-0.8750.h5\n",
      "21/21 [==============================] - 20s 1s/step - loss: 0.2785 - categorical_accuracy: 0.8964 - val_loss: 0.5316 - val_categorical_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2061 - categorical_accuracy: 0.9132\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.87500\n",
      "21/21 [==============================] - 19s 966ms/step - loss: 0.2061 - categorical_accuracy: 0.9132 - val_loss: 1.4426 - val_categorical_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1503 - categorical_accuracy: 0.9496\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.87500\n",
      "21/21 [==============================] - 20s 999ms/step - loss: 0.1503 - categorical_accuracy: 0.9496 - val_loss: 2.4006 - val_categorical_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1519 - categorical_accuracy: 0.9524\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.87500\n",
      "21/21 [==============================] - 20s 970ms/step - loss: 0.1519 - categorical_accuracy: 0.9524 - val_loss: 1.6502 - val_categorical_accuracy: 0.6875 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# hyperparameters\n",
    "kernel_size = (2, 2, 2)\n",
    "pool_size = (2, 2, 2)\n",
    "\n",
    "# model architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(32, kernel_size, input_shape=(frames, dim[0], dim[1], 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(64, kernel_size, activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(128, kernel_size, activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['categorical_accuracy'])\n",
    "\n",
    "# run & save the model\n",
    "run_model(model=model, batch_size=32, model_init = '3D_CNN', num_epochs=15, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028045b4",
   "metadata": {},
   "source": [
    "### 4. CNN-RNN Stack Architecture\n",
    "\n",
    "Another architecture to solve this problem is CNN+RNN stack. Here I use transfer learning methodology in CNN architecture.\n",
    "\n",
    "### Experiment-1 ResNet152V2 + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdd8635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ResNet152V2 (TimeDistribute  (None, 30, 4, 4, 2048)   58331648  \n",
      " d)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 30, 2048)         0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 30, 64)           131136    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30, 256)           16640     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 256)          1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 30, 128)           148224    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 30, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3840)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               983296    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,613,765\n",
      "Trainable params: 1,281,349\n",
      "Non-trainable params: 58,332,416\n",
      "_________________________________________________________________\n",
      "Steps per epoch =  11\n",
      "Validation steps =  2\n",
      "\n",
      "Source path =  /datasets/Project_data/train ; batch size = 64\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - ETA: 0s - loss: 2.3300 - categorical_accuracy: 0.3122\n",
      "Source path =  /datasets/Project_data/val ; batch size = 64\n",
      "11/11 [==============================] - 100s 8s/step - loss: 2.3300 - categorical_accuracy: 0.3122 - val_loss: 2.8747 - val_categorical_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 24s 2s/step - loss: 1.5397 - categorical_accuracy: 0.5929 - val_loss: 2.3454 - val_categorical_accuracy: 0.2969 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 24s 2s/step - loss: 1.7329 - categorical_accuracy: 0.5336 - val_loss: 3.0942 - val_categorical_accuracy: 0.1607 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 20s 2s/step - loss: 1.5348 - categorical_accuracy: 0.6395 - val_loss: 3.1798 - val_categorical_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 16s 1s/step - loss: 1.4449 - categorical_accuracy: 0.6651 - val_loss: 3.5231 - val_categorical_accuracy: 0.3750 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(tf.keras.applications.ResNet152V2(weights='imagenet', include_top=False),input_shape=(frames, dim[0], dim[1], 3), name='ResNet152V2', trainable=False))\n",
    "model.add(TimeDistributed(GlobalMaxPooling2D()))\n",
    "\n",
    "model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['categorical_accuracy'])\n",
    "\n",
    "# run model\n",
    "run_model(model=model, batch_size=64, num_epochs=5, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768c91b0",
   "metadata": {},
   "source": [
    "### Experiment-2 ResNet50V2 + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a22399b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ResNet50V2 (TimeDistributed  (None, 30, 4, 4, 2048)   23564800  \n",
      " )                                                               \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 30, 2048)         0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 30, 64)           131136    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30, 256)           16640     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 256)          1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 30, 128)           148224    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 30, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3840)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               983296    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,879,173\n",
      "Trainable params: 1,313,605\n",
      "Non-trainable params: 23,565,568\n",
      "_________________________________________________________________\n",
      "Steps per epoch =  11\n",
      "Validation steps =  2\n",
      "\n",
      "Source path =  /datasets/Project_data/train ; batch size = 64\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.9046 - categorical_accuracy: 0.2986\n",
      "Source path =  /datasets/Project_data/val ; batch size = 64\n",
      "11/11 [==============================] - 51s 4s/step - loss: 1.9046 - categorical_accuracy: 0.2986 - val_loss: 2.0406 - val_categorical_accuracy: 0.3300 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 19s 2s/step - loss: 1.0720 - categorical_accuracy: 0.6324 - val_loss: 1.9570 - val_categorical_accuracy: 0.3594 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 18s 2s/step - loss: 1.4710 - categorical_accuracy: 0.5455 - val_loss: 1.9968 - val_categorical_accuracy: 0.4107 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.3702 - categorical_accuracy: 0.5536 - val_loss: 2.6211 - val_categorical_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.9756 - categorical_accuracy: 0.6364 - val_loss: 1.3127 - val_categorical_accuracy: 0.3750 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False),input_shape=(frames, dim[0], dim[1], 3), name='ResNet50V2', trainable=False))\n",
    "model.add(TimeDistributed(GlobalMaxPooling2D()))\n",
    "\n",
    "model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['categorical_accuracy'])\n",
    "\n",
    "# run model\n",
    "run_model(model=model, batch_size=64, num_epochs=5, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89cc27a",
   "metadata": {},
   "source": [
    "### Experiment-3 ResNet152V2 + GRU with extra dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce1a8a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ResNet152V2 (TimeDistribute  (None, 30, 4, 4, 2048)   58331648  \n",
      " d)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 30, 2048)         0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 30, 64)           131136    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30, 256)           16640     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 256)          1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 30, 128)           148224    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 30, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3840)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               983296    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,646,021\n",
      "Trainable params: 1,313,605\n",
      "Non-trainable params: 58,332,416\n",
      "_________________________________________________________________\n",
      "Steps per epoch =  11\n",
      "Validation steps =  2\n",
      "\n",
      "Source path =  /datasets/Project_data/train ; batch size = 64\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.7841 - categorical_accuracy: 0.3122\n",
      "Source path =  /datasets/Project_data/val ; batch size = 64\n",
      "11/11 [==============================] - 64s 5s/step - loss: 1.7841 - categorical_accuracy: 0.3122 - val_loss: 1.9878 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 21s 2s/step - loss: 1.0118 - categorical_accuracy: 0.6285 - val_loss: 1.9455 - val_categorical_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 20s 2s/step - loss: 1.1751 - categorical_accuracy: 0.5929 - val_loss: 2.9253 - val_categorical_accuracy: 0.2321 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 17s 2s/step - loss: 1.2059 - categorical_accuracy: 0.5923 - val_loss: 1.9528 - val_categorical_accuracy: 0.2812 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 16s 1s/step - loss: 1.1763 - categorical_accuracy: 0.6172 - val_loss: 2.7108 - val_categorical_accuracy: 0.2188 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(tf.keras.applications.ResNet152V2(weights='imagenet', include_top=False),input_shape=(frames, dim[0], dim[1], 3), name='ResNet152V2', trainable=False))\n",
    "model.add(TimeDistributed(GlobalMaxPooling2D()))\n",
    "\n",
    "model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['categorical_accuracy'])\n",
    "\n",
    "# run model\n",
    "run_model(model=model, batch_size=64, num_epochs=5, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901746e6",
   "metadata": {},
   "source": [
    "### Experiment-4 MobileNet + GRU with dropouts (Best Model)\n",
    "\n",
    "- Input size = (100, 100, 3)\n",
    "- Batch size = 64\n",
    "- Time distributed `MobileNet` CNN layer with non trainable layers and weights used is `imagenet`\n",
    "- Time distributed Batch normalization layer\n",
    "- Time distributed max poolig layer with pool size of (2,2,2)\n",
    "- Time distributed Flatten layer\n",
    "- `GRU` layer with 256 neurons\n",
    "- Dropout layer with 0.2\n",
    "- Dense layers with 256 neurons and `relu` activation function.\n",
    "- Dropout layer with 0.2\n",
    "- Output layer with 5 neurons and `softmax` activation function.\n",
    "- Optimiser used is `Adam`\n",
    "- Loss used is `categorical_crossentropy`\n",
    "- Best accuracy\n",
    "    - Train: 92.12%\n",
    "    - Test: 87.50%\n",
    "- Best loss\n",
    "    - Train: 0.2935\n",
    "    - Test:  0.7299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "670852c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_gru (TimeDistribu  (None, 30, 3, 3, 1024)   3228864   \n",
      " ted)                                                            \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 30, 3, 3, 1024)   4096      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 30, 1, 1, 1024)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 30, 1024)         0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 256)               984576    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,284,613\n",
      "Trainable params: 1,053,701\n",
      "Non-trainable params: 3,230,912\n",
      "_________________________________________________________________\n",
      "Steps per epoch =  11\n",
      "Validation steps =  2\n",
      "\n",
      "Source path =  /datasets/Project_data/train ; batch size = 64\n",
      "Epoch 1/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.4477 - categorical_accuracy: 0.3816\n",
      "Source path =  /datasets/Project_data/val ; batch size = 64\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.41000, saving model to MobileNet_GRU_2024-09-0204_47_59.216946/model-00001-1.4477-0.3816-1.3590-0.4100.h5\n",
      "11/11 [==============================] - 46s 4s/step - loss: 1.4477 - categorical_accuracy: 0.3816 - val_loss: 1.3590 - val_categorical_accuracy: 0.4100 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8209 - categorical_accuracy: 0.7470\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.41000 to 0.51562, saving model to MobileNet_GRU_2024-09-0204_47_59.216946/model-00002-0.8209-0.7470-1.2433-0.5156.h5\n",
      "11/11 [==============================] - 20s 2s/step - loss: 0.8209 - categorical_accuracy: 0.7470 - val_loss: 1.2433 - val_categorical_accuracy: 0.5156 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8621 - categorical_accuracy: 0.6601\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.51562\n",
      "11/11 [==============================] - 18s 2s/step - loss: 0.8621 - categorical_accuracy: 0.6601 - val_loss: 1.5144 - val_categorical_accuracy: 0.4643 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6019 - categorical_accuracy: 0.8112\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.51562 to 0.59375, saving model to MobileNet_GRU_2024-09-0204_47_59.216946/model-00004-0.6019-0.8112-0.9366-0.5938.h5\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.6019 - categorical_accuracy: 0.8112 - val_loss: 0.9366 - val_categorical_accuracy: 0.5938 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4007 - categorical_accuracy: 0.8804\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.59375 to 0.62500, saving model to MobileNet_GRU_2024-09-0204_47_59.216946/model-00005-0.4007-0.8804-1.1193-0.6250.h5\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.4007 - categorical_accuracy: 0.8804 - val_loss: 1.1193 - val_categorical_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4099 - categorical_accuracy: 0.8421\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.62500 to 0.75000, saving model to MobileNet_GRU_2024-09-0204_47_59.216946/model-00006-0.4099-0.8421-0.9539-0.7500.h5\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.4099 - categorical_accuracy: 0.8421 - val_loss: 0.9539 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2935 - categorical_accuracy: 0.9212\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.75000 to 0.87500, saving model to MobileNet_GRU_2024-09-0204_47_59.216946/model-00007-0.2935-0.9212-0.7299-0.8750.h5\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.2935 - categorical_accuracy: 0.9212 - val_loss: 0.7299 - val_categorical_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2351 - categorical_accuracy: 0.9465\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.87500\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.2351 - categorical_accuracy: 0.9465 - val_loss: 1.0127 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3597 - categorical_accuracy: 0.8663\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.87500\n",
      "11/11 [==============================] - 10s 991ms/step - loss: 0.3597 - categorical_accuracy: 0.8663 - val_loss: 0.6494 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3281 - categorical_accuracy: 0.8663\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.87500\n",
      "11/11 [==============================] - 10s 996ms/step - loss: 0.3281 - categorical_accuracy: 0.8663 - val_loss: 1.5727 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2138 - categorical_accuracy: 0.9198\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.87500\n",
      "11/11 [==============================] - 10s 987ms/step - loss: 0.2138 - categorical_accuracy: 0.9198 - val_loss: 1.9070 - val_categorical_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2011 - categorical_accuracy: 0.9251\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.87500\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.2011 - categorical_accuracy: 0.9251 - val_loss: 0.3642 - val_categorical_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2674 - categorical_accuracy: 0.9037\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.87500\n",
      "11/11 [==============================] - 10s 1s/step - loss: 0.2674 - categorical_accuracy: 0.9037 - val_loss: 1.0488 - val_categorical_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2149 - categorical_accuracy: 0.9144\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.87500\n",
      "11/11 [==============================] - 10s 1s/step - loss: 0.2149 - categorical_accuracy: 0.9144 - val_loss: 1.5026 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2182 - categorical_accuracy: 0.9144\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.87500\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.2182 - categorical_accuracy: 0.9144 - val_loss: 2.0113 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# hyperparameter\n",
    "pool_size = (2,2)\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(tf.keras.applications.MobileNet(weights='imagenet', include_top=False), input_shape = (frames, dim[0], dim[1], 3),\n",
    "                          name = 'mobilenet_gru', trainable=False))\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size = pool_size)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(GRU(256))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# run & save the model\n",
    "run_model(model=model, batch_size=64, model_init = 'MobileNet_GRU', num_epochs=15, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
